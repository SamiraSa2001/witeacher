# WiTeacher

These are the introduction of the paper: [Mean Teacher-based Cross-Domain Activity Recognition using WiFi Signals](https://github.com/ChunjingXiao/WiTeacher/blob/master/MeanTeacher_WiTeacher_IoTJ.pdf), IEEE Internet of Things Journal, 2023. https://ieeexplore.ieee.org/document/10066505. 

WiTeacher aims at recognizing activities for cross-domain scenarios using WiFi Channel State Information (CSI).


# Citation
@ARTICLE{WiTeacher2023,  
&nbsp; &nbsp; author={Xiao, Chunjing and Lei, Yue and Liu, Chun and Wu, Jie},  
&nbsp; &nbsp; journal={IEEE Internet of Things Journal},   
&nbsp; &nbsp; title={Mean Teacher-based Cross-Domain Activity Recognition using WiFi Signals},   
&nbsp; &nbsp; year={2023},   
&nbsp; &nbsp; volume={10},   
&nbsp; &nbsp; number={14},   
&nbsp; &nbsp; pages={12787-12797},   
&nbsp; &nbsp; doi={10.1109/JIOT.2023.3256324}  
}

# Dataset


The two public datasets used in the paper are shown below.


## DeepSeg Dataset


The data that we extract from raw CSI data for our experiments can be downloaded from Baidu Netdisk or Google Drive:


Data of CSI amplitudes: Data_CsiAmplitudeCut Baidu Netdisk: https://pan.baidu.com/s/12DwlT58PzlVAyBc-lYx1lw (Password: k8yp) 
or Google Drive: https://drive.google.com/drive/folders/1PLzV6ZWAauMQLf08NUkd5UeKrqyGMHgv


Manually marked Labels for CSI amplitude data: Label_CsiAmplitudeCut Baidu: https://pan.baidu.com/s/1nY5Og4NlLb7VH5oBQ-LH9w (Password: xnra) 
or Google: https://drive.google.com/drive/folders/1855zX-93QjmAt2wSeJk0rTJRiPaFMGBd (1 boxing; 2 hand swing; 3 picking up; 4 hand raising; 5 running; 6 pushing; 7 squatting; 8 drawing O; 9 walking; 10 drawing X)



Also the raw CSI data we collected can be downloaded via Baidu or Google: Data_RawCSIDat. Note that there is no need to download the raw CSI data for running our experiments. Downloading Data_CsiAmplitudeCut and Label_CsiAmplitudeCut is enough for our experiments. Baidu: https://pan.baidu.com/s/1FpA2u_fzFIh4FuNIcWOPdQ (Password: hhcv) or Google: https://drive.google.com/drive/folders/1vUeJYChsDgBzv7bJbiKDEfAHQje3SW9G




## SignFi Dataset

The SignFi dataset comes from the link below: https://github.com/yongsen/SignFi



# Motivation for WiTeacher

Despite of significant success of these methods, there still
exist some shortages. First, few-shot learning-based methods
still need a few labeled samples from the terminal users. But collecting a few labeled samples is still difficult,
especially for old terminal users. Second, data augmentation-based methods generally consider all the generated data to possess the same quality. However, GANs are typically unstable
and prone to failure, and correspondingly generated
samples may exhibit various levels of quality, i.e., some may
be like real samples and others may be quite noised. Third,
existing methods only consider each sample separately during
model training, and ignore the relationships between samples,
which can be explored to enhance model robustness.

To address these issues, we present a Mean Teacher-based
cross-domain activity recognition framework using WiFi CSI.



# WiTeacher Overview

In WiTeacher framework, we designed a adaptive
label smoothing method to produce proper soft labels for
target-like samples generated by StyleGAN. Based on these
target-like samples with soft labels, we built a label smoothing-based classification loss to promote the generalization capacity
of the model. Further, we presented a sample relation-based
consistency regularization term to force the distance of two
samples to be consistent with the augmented ones, which can
make the model more robust.

![Figure](https://raw.githubusercontent.com/ChunjingXiao/WiTeacher/main/FigWiTeacherFramework.jpg)
<p align="center">Figure 1. WiTeacher Framework. </p>

Figure 1 presents an illustration of how the proposed framework works. 
Here ($x_l$, $y$), $\left( {{\hat x_l},\hat y} \right)$, $x_u$ and $\hat x_u$ refer to source samples with labels, generated target-like samples with soft labels, unlabeled target samples and generated source-like samples respectively. During the training process, first, $x_l$ is transferred into target-like sample ${\hat x_l}$ by generator ${G_1}$ and $y$ into soft label ${\hat y}$ by our designed adaptive label smoothing method. And $\left( {{\hat x_l},\hat y} \right)$ and $\left( {{x_l},y} \right)$ are adopted to build the label smoothing-based classification loss and standard classification loss individually. Second, $x_u$ is transferred into source-like sample ${\hat x_u}$ by generator ${G_2}$, and sample pairs $\left( {x_u^i,x_u^{i + j}} \right)$ and $\left( {\hat x_u^i,\hat x_u^{i + j}} \right)$ extracted from them are used to build the sample relation-based consistency loss. Besides, $x_u$ is utilized to construct the standard consistency loss.
